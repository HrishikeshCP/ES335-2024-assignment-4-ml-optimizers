{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import pandas\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history, filename='diagnostics_plot.png'):\n",
    "    # Plot loss and accuracy curves\n",
    "    pyplot.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Loss')\n",
    "    pyplot.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Accuracy')\n",
    "    pyplot.legend()\n",
    "\n",
    "    # Save plot to file\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG (1 block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg1_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_11768\\59701725.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
      "c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_vgg1_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "\t\tclass_mode='binary', batch_size=20, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "\t\tclass_mode='binary', batch_size=10, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history, 'vgg1_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG (3 blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg3_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_10664\\4090967136.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
      "c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_10664\\4090967136.py:16: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 67.500\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_vgg3_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "\t\tclass_mode='binary', batch_size=20, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "\t\tclass_mode='binary', batch_size=10, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history, 'vgg3_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG (3 blocks) with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg3_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_10664\\4236747305.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
      "c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_10664\\4236747305.py:18: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 82.500\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_vgg1_model()\n",
    "\t# create data generators\n",
    "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "\t\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = train_datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "\t\tclass_mode='binary', batch_size=20, target_size=(200, 200))\n",
    "\ttest_it = test_datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "\t\tclass_mode='binary', batch_size=10, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=0)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history, 'vgg3_da_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using VGG16 or VGG19 with tuning all layers (including tuning convolution layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_20276\\3861725156.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # Unfreeze all layers for fine-tuning\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterator\n",
    "    train_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "        class_mode='binary', batch_size=20, target_size=(224, 224))\n",
    "    test_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "        class_mode='binary', batch_size=10, target_size=(224, 224))\n",
    "    # fit model\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history, 'tf_vgg16_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
