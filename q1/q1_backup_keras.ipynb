{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import pandas\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history, filename='diagnostics_plot.png'):\n",
    "    # Plot loss and accuracy curves\n",
    "    pyplot.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Loss')\n",
    "    pyplot.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.ylabel('Accuracy')\n",
    "    pyplot.legend()\n",
    "\n",
    "    # Save plot to file\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG (1 block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg1_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\1701010363.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 12.6080 - accuracy: 0.5125 - val_loss: 0.7058 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6975 - accuracy: 0.4938 - val_loss: 0.6911 - val_accuracy: 0.4500\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6837 - accuracy: 0.5562 - val_loss: 0.6916 - val_accuracy: 0.4250\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.6669 - accuracy: 0.7625 - val_loss: 0.6867 - val_accuracy: 0.4500\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6375 - accuracy: 0.7937 - val_loss: 0.6809 - val_accuracy: 0.4500\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.6042 - accuracy: 0.7437 - val_loss: 0.6919 - val_accuracy: 0.4750\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.5545 - accuracy: 0.7625 - val_loss: 0.7251 - val_accuracy: 0.4750\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.5092 - accuracy: 0.8000 - val_loss: 0.7505 - val_accuracy: 0.4750\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4498 - accuracy: 0.7688 - val_loss: 0.7172 - val_accuracy: 0.5000\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 5s 2s/step - loss: 0.3874 - accuracy: 0.8687 - val_loss: 0.6983 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3346 - accuracy: 0.8687 - val_loss: 0.6123 - val_accuracy: 0.6250\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.2131 - accuracy: 0.9625 - val_loss: 0.6284 - val_accuracy: 0.7000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1633 - accuracy: 0.9812 - val_loss: 0.6500 - val_accuracy: 0.6250\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.1118 - accuracy: 0.9875 - val_loss: 0.6337 - val_accuracy: 0.7250\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.6250\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0603 - accuracy: 0.9875 - val_loss: 0.7311 - val_accuracy: 0.6750\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0374 - accuracy: 0.9937 - val_loss: 0.9043 - val_accuracy: 0.6750\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.7750\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.6500\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.7288 - val_accuracy: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\1701010363.py:16: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 67.500\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_vgg1_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "\t\tclass_mode='binary', batch_size=50, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "\t\tclass_mode='binary', batch_size=20, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history, 'vgg1_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG (3 blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg3_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\984914352.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 2.9059 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5750\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6884 - accuracy: 0.5500 - val_loss: 0.6896 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6871 - accuracy: 0.4500 - val_loss: 0.7246 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6628 - accuracy: 0.5375 - val_loss: 0.7761 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6634 - accuracy: 0.5875 - val_loss: 0.6718 - val_accuracy: 0.5250\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.5924 - accuracy: 0.7125 - val_loss: 0.6600 - val_accuracy: 0.5750\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5608 - accuracy: 0.7312 - val_loss: 0.6125 - val_accuracy: 0.6750\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4941 - accuracy: 0.8000 - val_loss: 0.6693 - val_accuracy: 0.6000\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4787 - accuracy: 0.7188 - val_loss: 0.5465 - val_accuracy: 0.6750\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4264 - accuracy: 0.8125 - val_loss: 0.6998 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3944 - accuracy: 0.7812 - val_loss: 0.7116 - val_accuracy: 0.5750\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4100 - accuracy: 0.7625 - val_loss: 0.6849 - val_accuracy: 0.7000\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3899 - accuracy: 0.8313 - val_loss: 0.6252 - val_accuracy: 0.6500\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3197 - accuracy: 0.9062 - val_loss: 0.5312 - val_accuracy: 0.6750\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.2583 - accuracy: 0.9250 - val_loss: 0.5479 - val_accuracy: 0.6750\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1837 - accuracy: 0.9563 - val_loss: 0.5742 - val_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.1403 - accuracy: 0.9688 - val_loss: 0.6085 - val_accuracy: 0.7250\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.1146 - accuracy: 0.9812 - val_loss: 0.6905 - val_accuracy: 0.6750\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0874 - accuracy: 0.9688 - val_loss: 0.6243 - val_accuracy: 0.6750\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0791 - accuracy: 0.9812 - val_loss: 0.5921 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\984914352.py:16: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 75.000\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_vgg3_model()\n",
    "\t# create data generator\n",
    "\tdatagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "\t\tclass_mode='binary', batch_size=50, target_size=(200, 200))\n",
    "\ttest_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "\t\tclass_mode='binary', batch_size=20, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history, 'vgg3_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG (3 blocks) with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_vgg3_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\1723787229.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 8s 2s/step - loss: 12.5311 - accuracy: 0.3938 - val_loss: 0.7165 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7057 - accuracy: 0.4750 - val_loss: 0.6912 - val_accuracy: 0.4250\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6790 - accuracy: 0.6187 - val_loss: 0.7262 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.7126 - accuracy: 0.4750 - val_loss: 0.7240 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6841 - accuracy: 0.5312 - val_loss: 0.7185 - val_accuracy: 0.5250\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6714 - accuracy: 0.5813 - val_loss: 0.7039 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6598 - accuracy: 0.5625 - val_loss: 0.7044 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6601 - accuracy: 0.5750 - val_loss: 0.7256 - val_accuracy: 0.5250\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6455 - accuracy: 0.5938 - val_loss: 0.8066 - val_accuracy: 0.4250\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6522 - accuracy: 0.6187 - val_loss: 0.7658 - val_accuracy: 0.3750\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6210 - accuracy: 0.6438 - val_loss: 0.7069 - val_accuracy: 0.5000\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6015 - accuracy: 0.6562 - val_loss: 0.7269 - val_accuracy: 0.5250\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6230 - accuracy: 0.6625 - val_loss: 0.7342 - val_accuracy: 0.4750\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6088 - accuracy: 0.6438 - val_loss: 0.6760 - val_accuracy: 0.5500\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.6279 - accuracy: 0.5938 - val_loss: 0.6003 - val_accuracy: 0.6500\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5696 - accuracy: 0.7250 - val_loss: 0.7133 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5525 - accuracy: 0.7125 - val_loss: 0.5678 - val_accuracy: 0.7000\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5365 - accuracy: 0.7437 - val_loss: 0.5758 - val_accuracy: 0.7000\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5175 - accuracy: 0.7688 - val_loss: 0.5689 - val_accuracy: 0.6500\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 7s 1s/step - loss: 0.4827 - accuracy: 0.7937 - val_loss: 0.5553 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\1723787229.py:18: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 70.000\n"
     ]
    }
   ],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# define model\n",
    "\tmodel = define_vgg1_model()\n",
    "\t# create data generators\n",
    "\ttrain_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "\t\twidth_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "\ttest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\t# prepare iterators\n",
    "\ttrain_it = train_datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "\t\tclass_mode='binary', batch_size=50, target_size=(200, 200))\n",
    "\ttest_it = test_datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "\t\tclass_mode='binary', batch_size=20, target_size=(200, 200))\n",
    "\t# fit model\n",
    "\thistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "\t\tvalidation_data=test_it, validation_steps=len(test_it), epochs=20, verbose=1)\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(history, 'vgg3_da_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using VGG16 or VGG19 with tuning all layers (including tuning convolution layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\3665970147.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/4 [======>.......................] - ETA: 19s - loss: 6.9852 - accuracy: 0.5000"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # Unfreeze all layers for fine-tuning\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterator\n",
    "    train_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "        class_mode='binary', batch_size=50, target_size=(224, 224))\n",
    "    test_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "        class_mode='binary', batch_size=20, target_size=(224, 224))\n",
    "    # fit model\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history, 'tf_vgg16_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\2902955834.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 377.3153 - accuracy: 0.4875 - val_loss: 138.8708 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 25s 6s/step - loss: 51.7495 - accuracy: 0.8250 - val_loss: 40.4385 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 10.0784 - accuracy: 0.9500 - val_loss: 841.5875 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 27s 8s/step - loss: 340.3561 - accuracy: 0.9250 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 26s 8s/step - loss: 374.8050 - accuracy: 0.9250 - val_loss: 38.4491 - val_accuracy: 0.8500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 26s 8s/step - loss: 445.7976 - accuracy: 0.8562 - val_loss: 4.2437 - val_accuracy: 0.9750\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 125.6913 - accuracy: 0.9500 - val_loss: 169.2706 - val_accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 31s 7s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.0297 - accuracy: 0.9812 - val_loss: 0.0701 - val_accuracy: 0.9250\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 27s 8s/step - loss: 0.0479 - accuracy: 0.9500 - val_loss: 0.0703 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_292\\2902955834.py:36: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 92.500\n"
     ]
    }
   ],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterator\n",
    "    train_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/train/',\n",
    "        class_mode='binary', batch_size=50, target_size=(224, 224))\n",
    "    test_it = datagen.flow_from_directory('monkey_vs_rabbit_dataset/test/',\n",
    "        class_mode='binary', batch_size=20, target_size=(224, 224))\n",
    "    # fit model\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=10, verbose=1)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history, 'tf_vgg16_plot.png')\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.9115\n",
      "Epoch 2/30, Loss: 0.7663\n",
      "Epoch 3/30, Loss: 0.8006\n",
      "Epoch 4/30, Loss: 0.7772\n",
      "Epoch 5/30, Loss: 0.6969\n",
      "Epoch 6/30, Loss: 0.6884\n",
      "Epoch 7/30, Loss: 0.6920\n",
      "Epoch 8/30, Loss: 0.6952\n",
      "Epoch 9/30, Loss: 0.6940\n",
      "Epoch 10/30, Loss: 0.6910\n",
      "Epoch 11/30, Loss: 0.6883\n",
      "Epoch 12/30, Loss: 0.6888\n",
      "Epoch 13/30, Loss: 0.6863\n",
      "Epoch 14/30, Loss: 0.6894\n",
      "Epoch 15/30, Loss: 0.6868\n",
      "Epoch 16/30, Loss: 0.6855\n",
      "Epoch 17/30, Loss: 0.6788\n",
      "Epoch 18/30, Loss: 0.6762\n",
      "Epoch 19/30, Loss: 0.6954\n",
      "Epoch 20/30, Loss: 0.6818\n",
      "Epoch 21/30, Loss: 0.6772\n",
      "Epoch 22/30, Loss: 0.6706\n",
      "Epoch 23/30, Loss: 0.6559\n",
      "Epoch 24/30, Loss: 0.6475\n",
      "Epoch 25/30, Loss: 0.6662\n",
      "Epoch 26/30, Loss: 0.6230\n",
      "Epoch 27/30, Loss: 0.6273\n",
      "Epoch 28/30, Loss: 0.6444\n",
      "Epoch 29/30, Loss: 0.6129\n",
      "Epoch 30/30, Loss: 0.6618\n",
      "Accuracy on test set: 55.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Model Definition\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(200 * 200 * 3, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = torch.sigmoid(self.fc7(x))\n",
    "        return x\n",
    "\n",
    "# Data Transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Data Loaders\n",
    "train_dataset = datasets.ImageFolder('monkey_vs_rabbit_dataset/train/', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder('monkey_vs_rabbit_dataset/test/', transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Model, Loss, and Optimizer Setup\n",
    "model = MLP()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Validation Loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        outputs = model(images)\n",
    "        predicted = torch.round(outputs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy on test set: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
